{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from librosa.feature import zero_crossing_rate, mfcc, spectral_centroid, spectral_rolloff, spectral_bandwidth, rms\n",
    "import os\n",
    "from scipy import signal\n",
    "import soundfile\n",
    "\n",
    "# Constants\n",
    "DEFAULT_SAMPLE_RATE = 44100\n",
    "DEFAULT_FRAME_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_audio_file(audio_file, range_size=5, sr=DEFAULT_SAMPLE_RATE):\n",
    "    play_list = list()\n",
    "    offset = 0\n",
    "    for offset in range(range_size):\n",
    "        extra = '-' + str(sr) + '-' + str(offset)\n",
    "        base = os.path.basename(audio_file)\n",
    "        audio_data, sr_res = librosa.load(audio_file, sr=sr, mono=True, offset=offset, duration=5.0)\n",
    "        soundfile.write('E:\\\\Source\\\\cryingbaby\\\\teste-filtro-audio\\\\baby_cry_detection\\\\baby_cry_detection\\\\prediction_simulation\\\\offset_test\\\\' + \\\n",
    "            base[:-4] + extra + base[-4:], \\\n",
    "            data=audio_data, samplerate=sr_res)\n",
    "        play_list.append(audio_data)\n",
    "    return play_list\n",
    "\n",
    "\n",
    "examples = glob.glob('E:\\\\Source\\\\cryingbaby\\\\teste-filtro-audio\\\\baby_cry_detection\\\\baby_cry_detection\\\\prediction_simulation\\\\*.ogg')\n",
    "\n",
    "for example in examples:\n",
    "    offset_audio_file(example)\n",
    "\n",
    "# def get_features(audio_data, sr=DEFAULT_SAMPLE_RATE, filter=None):\n",
    "\n",
    "#     # Teste filtrando as frequÃªncias de fala\n",
    "#     if filter:\n",
    "#         audio_data, sr = filter(audio_data, sr)\n",
    "   \n",
    "#     zcr_feat = zero_crossing_rate(y=audio_data, hop_length=DEFAULT_FRAME_SIZE)\n",
    "#     rmse_feat = rms(y=audio_data, hop_length=DEFAULT_FRAME_SIZE)\n",
    "#     mfcc_feat = mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "#     spectral_centroid_feat = spectral_centroid(y=audio_data, sr=sr, hop_length=DEFAULT_FRAME_SIZE)\n",
    "#     spectral_rolloff_feat = spectral_rolloff(y=audio_data, sr=sr, hop_length=DEFAULT_FRAME_SIZE, roll_percent=0.90)\n",
    "#     spectral_bandwidth_feat = spectral_bandwidth(y=audio_data, sr=sr, hop_length=DEFAULT_FRAME_SIZE)\n",
    "\n",
    "#     concat_feat = np.concatenate((zcr_feat,\n",
    "#                                     rmse_feat,\n",
    "#                                     mfcc_feat,\n",
    "#                                     spectral_centroid_feat,\n",
    "#                                     spectral_rolloff_feat,\n",
    "#                                     spectral_bandwidth_feat\n",
    "#                                     ), axis=0)\n",
    "\n",
    "#     mean_feat = np.mean(concat_feat, axis=1, keepdims=True).transpose()\n",
    "#     return mean_feat\n",
    "\n",
    "# for audio_file in glob.glob(\"data/**/*.*\"):\n",
    "#     ### TODO: Checar se tem que usar todo o offset\n",
    "#     mean_feat = get_features(offset_audio_file(audio_file, 1)[0])\n",
    "\n",
    "#     X = np.concatenate((X, mean_feat), axis=0)\n",
    "\n",
    "#     label = os.path.dirname(audio_file)\n",
    "#     y.append(label)\n",
    "\n",
    "# X"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f97f74657bfe1bb9b50ae1a45b7f5757271fed5f90737f9cf6d9ba079971827"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv-bcd': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
